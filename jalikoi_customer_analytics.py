#!/usr/bin/env python3
"""
Jalikoi Customer Analytics Engine
==================================
Comprehensive ML-powered customer insights system

Features:
1. Customer Lifetime Value (CLV) Prediction
2. Churn Prediction
3. Loyalty Segmentation
4. Purchase Pattern Analysis
5. Station Affinity Analysis
6. Peak Hour Identification
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
import warnings
warnings.filterwarnings('ignore')

class JalikoiCustomerAnalytics:
    """Main analytics engine for customer insights"""
    
    def __init__(self, data_path):
        """Initialize with payment data"""
        self.df = pd.read_csv(data_path)
        self._preprocess_data()
        self._engineer_features()
        
    def _preprocess_data(self):
        """Clean and prepare data"""
        # Convert dates
        self.df['created_at'] = pd.to_datetime(self.df['created_at'], format='%d/%m/%Y %H:%M')
        self.df['date'] = self.df['created_at'].dt.date
        self.df['hour'] = self.df['created_at'].dt.hour
        self.df['day_of_week'] = self.df['created_at'].dt.dayofweek
        
        # Filter successful transactions only for most analyses
        self.df_success = self.df[self.df['payment_status'] == 200].copy()
        
        # Calculate reference date (most recent date in data)
        self.reference_date = self.df['created_at'].max()
        
    def _engineer_features(self):
        """Create customer-level features"""
        # Customer metrics from successful transactions
        customer_metrics = self.df_success.groupby('motorcyclist_id').agg({
            'id': 'count',  # transaction_count
            'amount': ['sum', 'mean', 'std', 'min', 'max'],
            'liter': ['sum', 'mean'],
            'station_id': lambda x: x.nunique(),  # station_diversity
            'created_at': ['min', 'max'],
            'payment_method_id': 'first',
            'source': lambda x: (x == 'APP').sum() / len(x)  # app_usage_rate
        }).reset_index()
        
        customer_metrics.columns = [
            'motorcyclist_id', 'transaction_count', 'total_spent', 'avg_transaction',
            'std_transaction', 'min_transaction', 'max_transaction',
            'total_liters', 'avg_liters', 'station_diversity', 
            'first_transaction', 'last_transaction', 'payment_method', 'app_usage_rate'
        ]
        
        # Calculate recency, frequency, monetary (RFM)
        customer_metrics['recency_days'] = (
            self.reference_date - customer_metrics['last_transaction']
        ).dt.total_seconds() / (24 * 3600)
        
        customer_metrics['customer_age_days'] = (
            customer_metrics['last_transaction'] - customer_metrics['first_transaction']
        ).dt.total_seconds() / (24 * 3600)
        
        # Avoid division by zero
        customer_metrics['customer_age_days'] = customer_metrics['customer_age_days'].replace(0, 0.1)
        
        # Calculate frequency (transactions per day)
        customer_metrics['frequency'] = (
            customer_metrics['transaction_count'] / customer_metrics['customer_age_days']
        )
        
        # Calculate failure rate per customer
        failure_rates = self.df.groupby('motorcyclist_id').agg({
            'payment_status': lambda x: (x == 500).sum() / len(x)
        }).reset_index()
        failure_rates.columns = ['motorcyclist_id', 'failure_rate']
        
        customer_metrics = customer_metrics.merge(failure_rates, on='motorcyclist_id', how='left')
        customer_metrics['failure_rate'] = customer_metrics['failure_rate'].fillna(0)
        
        self.customer_metrics = customer_metrics
        
    def predict_clv(self, months_ahead=6):
        """
        Predict Customer Lifetime Value
        
        CLV = Average Transaction Value √ó Transaction Frequency √ó Customer Lifespan
        """
        print("=" * 80)
        print("CUSTOMER LIFETIME VALUE (CLV) PREDICTION")
        print("=" * 80)
        
        # Calculate projected CLV
        days_ahead = months_ahead * 30
        
        self.customer_metrics['predicted_transactions'] = (
            self.customer_metrics['frequency'] * days_ahead
        )
        
        self.customer_metrics['predicted_clv_6m'] = (
            self.customer_metrics['predicted_transactions'] * 
            self.customer_metrics['avg_transaction']
        )
        
        # Adjust for churn probability (if available)
        # For now, use simple heuristic: reduce CLV for customers with high recency
        churn_factor = np.clip(1 - (self.customer_metrics['recency_days'] / 30), 0.1, 1.0)
        self.customer_metrics['predicted_clv_6m_adjusted'] = (
            self.customer_metrics['predicted_clv_6m'] * churn_factor
        )
        
        # Categorize customers
        clv_percentiles = self.customer_metrics['predicted_clv_6m_adjusted'].quantile([0.33, 0.67])
        
        def categorize_clv(value):
            if value >= clv_percentiles.iloc[1]:
                return 'High Value'
            elif value >= clv_percentiles.iloc[0]:
                return 'Medium Value'
            else:
                return 'Low Value'
        
        self.customer_metrics['clv_category'] = (
            self.customer_metrics['predicted_clv_6m_adjusted'].apply(categorize_clv)
        )
        
        # Display results
        print(f"\nüìä CLV Summary (Next {months_ahead} months):")
        print(f"   Average CLV: RWF {self.customer_metrics['predicted_clv_6m_adjusted'].mean():,.2f}")
        print(f"   Median CLV: RWF {self.customer_metrics['predicted_clv_6m_adjusted'].median():,.2f}")
        print(f"   Top 20% CLV: RWF {self.customer_metrics['predicted_clv_6m_adjusted'].quantile(0.8):,.2f}")
        
        print("\nüéØ Customer Value Distribution:")
        clv_dist = self.customer_metrics['clv_category'].value_counts()
        for category, count in clv_dist.items():
            pct = (count / len(self.customer_metrics)) * 100
            print(f"   {category}: {count} customers ({pct:.1f}%)")
        
        # Top 10 customers by CLV
        print("\nüèÜ Top 10 High-Value Customers (Next 6 months):")
        top_customers = self.customer_metrics.nlargest(10, 'predicted_clv_6m_adjusted')[
            ['motorcyclist_id', 'predicted_clv_6m_adjusted', 'total_spent', 
             'transaction_count', 'frequency', 'recency_days']
        ]
        print(top_customers.to_string(index=False))
        
        return self.customer_metrics[['motorcyclist_id', 'predicted_clv_6m_adjusted', 'clv_category']]
    
    def predict_churn(self):
        """
        Identify customers at risk of churning
        
        Churn indicators:
        - High recency (haven't transacted recently)
        - Decreasing frequency
        - High failure rate
        - Low engagement
        """
        print("\n" + "=" * 80)
        print("CHURN PREDICTION ANALYSIS")
        print("=" * 80)
        
        # Calculate churn risk score (0-100)
        # Higher recency = higher risk
        recency_score = np.clip((self.customer_metrics['recency_days'] / 7) * 20, 0, 40)
        
        # Lower frequency = higher risk
        freq_percentile = self.customer_metrics['frequency'].rank(pct=True)
        frequency_score = (1 - freq_percentile) * 30
        
        # Higher failure rate = higher risk
        failure_score = self.customer_metrics['failure_rate'] * 20
        
        # Lower transaction count = higher risk (less committed)
        txn_percentile = self.customer_metrics['transaction_count'].rank(pct=True)
        commitment_score = (1 - txn_percentile) * 10
        
        self.customer_metrics['churn_risk_score'] = (
            recency_score + frequency_score + failure_score + commitment_score
        )
        
        # Categorize churn risk
        def categorize_churn(score):
            if score >= 60:
                return 'High Risk'
            elif score >= 35:
                return 'Medium Risk'
            else:
                return 'Low Risk'
        
        self.customer_metrics['churn_risk'] = (
            self.customer_metrics['churn_risk_score'].apply(categorize_churn)
        )
        
        print("\n‚ö†Ô∏è  Churn Risk Distribution:")
        churn_dist = self.customer_metrics['churn_risk'].value_counts()
        for risk, count in churn_dist.items():
            pct = (count / len(self.customer_metrics)) * 100
            print(f"   {risk}: {count} customers ({pct:.1f}%)")
        
        # High-value customers at risk
        high_value_at_risk = self.customer_metrics[
            (self.customer_metrics['clv_category'] == 'High Value') &
            (self.customer_metrics['churn_risk'] == 'High Risk')
        ]
        
        print(f"\nüö® CRITICAL: {len(high_value_at_risk)} High-Value customers at HIGH CHURN RISK!")
        print(f"   Potential revenue at risk: RWF {high_value_at_risk['predicted_clv_6m_adjusted'].sum():,.2f}")
        
        # Show at-risk customers
        if len(high_value_at_risk) > 0:
            print("\nüî¥ High-Value Customers to Contact IMMEDIATELY:")
            at_risk_detail = high_value_at_risk[
                ['motorcyclist_id', 'predicted_clv_6m_adjusted', 'recency_days', 
                 'transaction_count', 'failure_rate', 'churn_risk_score']
            ].nlargest(10, 'predicted_clv_6m_adjusted')
            print(at_risk_detail.to_string(index=False))
        
        return self.customer_metrics[['motorcyclist_id', 'churn_risk', 'churn_risk_score']]
    
    def segment_customers(self):
        """
        Loyalty Segmentation using RFM + ML clustering
        
        Segments:
        - Champions: High value, frequent, recent
        - Loyal Customers: Frequent buyers
        - Potential Loyalists: Recent customers with potential
        - At Risk: Were valuable but haven't returned
        - Can't Lose Them: High value but churning
        - Hibernating: Low engagement
        - Lost: Haven't been seen in a while
        """
        print("\n" + "=" * 80)
        print("LOYALTY SEGMENTATION")
        print("=" * 80)
        
        # RFM Scoring (1-5 scale) - using rank-based percentiles for small datasets
        def score_metric(series, reverse=False):
            """Score a metric from 1-5 based on percentile"""
            percentiles = series.rank(pct=True)
            if reverse:
                percentiles = 1 - percentiles
            return np.ceil(percentiles * 5).clip(1, 5)
        
        self.customer_metrics['R_score'] = score_metric(self.customer_metrics['recency_days'], reverse=True)
        self.customer_metrics['F_score'] = score_metric(self.customer_metrics['transaction_count'])
        self.customer_metrics['M_score'] = score_metric(self.customer_metrics['total_spent'])
        
        # Create segment based on RFM
        def assign_segment(row):
            R, F, M = row['R_score'], row['F_score'], row['M_score']
            
            if R >= 4 and F >= 4 and M >= 4:
                return 'Champions'
            elif R >= 3 and F >= 3 and M >= 3:
                return 'Loyal Customers'
            elif R >= 4 and F <= 2:
                return 'Potential Loyalists'
            elif R <= 2 and F >= 3 and M >= 3:
                return 'At Risk'
            elif R <= 2 and F >= 4 and M >= 4:
                return "Can't Lose Them"
            elif R <= 2 and F <= 2 and M <= 2:
                return 'Lost'
            elif R == 3 and F <= 2:
                return 'Hibernating'
            else:
                return 'Need Attention'
        
        self.customer_metrics['segment'] = self.customer_metrics.apply(assign_segment, axis=1)
        
        print("\nüë• Customer Segments:")
        segment_summary = self.customer_metrics.groupby('segment').agg({
            'motorcyclist_id': 'count',
            'total_spent': 'sum',
            'avg_transaction': 'mean',
            'frequency': 'mean',
            'recency_days': 'mean'
        }).round(2)
        
        segment_summary.columns = ['Count', 'Total Revenue', 'Avg Transaction', 'Frequency', 'Avg Recency']
        segment_summary['% of Customers'] = (segment_summary['Count'] / segment_summary['Count'].sum() * 100).round(1)
        segment_summary['% of Revenue'] = (segment_summary['Total Revenue'] / segment_summary['Total Revenue'].sum() * 100).round(1)
        
        print(segment_summary.sort_values('Total Revenue', ascending=False).to_string())
        
        # Actionable recommendations
        print("\nüí° SEGMENT-SPECIFIC RECOMMENDATIONS:")
        
        segments = self.customer_metrics['segment'].value_counts()
        for seg in segments.index:
            count = segments[seg]
            if seg == 'Champions':
                print(f"\n   üèÜ {seg} ({count} customers):")
                print("      ‚Üí Reward with exclusive perks, VIP treatment")
                print("      ‚Üí Ask for referrals and testimonials")
                print("      ‚Üí Offer premium services or loyalty program")
            elif seg == 'Loyal Customers':
                print(f"\n   üíô {seg} ({count} customers):")
                print("      ‚Üí Upsell opportunities (larger tank fills)")
                print("      ‚Üí Early access to promotions")
                print("      ‚Üí Build emotional connection")
            elif seg == 'At Risk':
                print(f"\n   ‚ö†Ô∏è  {seg} ({count} customers):")
                print("      ‚Üí Send personalized win-back campaigns")
                print("      ‚Üí Offer special 'we miss you' discounts")
                print("      ‚Üí Survey to understand issues")
            elif seg == "Can't Lose Them":
                print(f"\n   üö® {seg} ({count} customers):")
                print("      ‚Üí URGENT: Personal outreach required")
                print("      ‚Üí Aggressive retention offers")
                print("      ‚Üí Executive-level engagement")
            elif seg == 'Potential Loyalists':
                print(f"\n   üå± {seg} ({count} customers):")
                print("      ‚Üí Nurture with onboarding content")
                print("      ‚Üí Encourage repeat purchases with incentives")
                print("      ‚Üí Educate on app features")
            elif seg == 'Hibernating':
                print(f"\n   üò¥ {seg} ({count} customers):")
                print("      ‚Üí Re-engagement campaigns")
                print("      ‚Üí Special comeback offers")
                print("      ‚Üí Remind of benefits")
            elif seg == 'Lost':
                print(f"\n   üíî {seg} ({count} customers):")
                print("      ‚Üí Low-cost win-back attempt")
                print("      ‚Üí Understand why they left")
                print("      ‚Üí Consider removing from active marketing")
        
        return self.customer_metrics[['motorcyclist_id', 'segment', 'R_score', 'F_score', 'M_score']]
    
    def analyze_purchase_patterns(self):
        """
        Analyze typical refueling cycles per motorcyclist
        """
        print("\n" + "=" * 80)
        print("PURCHASE PATTERN ANALYSIS")
        print("=" * 80)
        
        # Calculate days between transactions for each customer
        purchase_intervals = []
        
        for customer_id in self.df_success['motorcyclist_id'].unique():
            customer_txns = self.df_success[
                self.df_success['motorcyclist_id'] == customer_id
            ].sort_values('created_at')
            
            if len(customer_txns) > 1:
                intervals = customer_txns['created_at'].diff().dt.total_seconds() / (24 * 3600)
                intervals = intervals[intervals > 0]  # Remove first NaN and any zeros
                
                if len(intervals) > 0:
                    purchase_intervals.append({
                        'motorcyclist_id': customer_id,
                        'avg_days_between_refuel': intervals.mean(),
                        'std_days_between_refuel': intervals.std() if len(intervals) > 1 else 0,
                        'min_days': intervals.min(),
                        'max_days': intervals.max(),
                        'refuel_regularity': 1 / (intervals.std() + 1) if len(intervals) > 1 else 0
                    })
        
        if purchase_intervals:
            pattern_df = pd.DataFrame(purchase_intervals)
            
            # Merge with customer metrics
            self.customer_metrics = self.customer_metrics.merge(
                pattern_df, on='motorcyclist_id', how='left'
            )
            
            print("\n‚è±Ô∏è  Refueling Cycle Insights:")
            print(f"   Average days between refuels: {pattern_df['avg_days_between_refuel'].mean():.1f} days")
            print(f"   Most frequent refueler: Every {pattern_df['avg_days_between_refuel'].min():.1f} days")
            print(f"   Least frequent: Every {pattern_df['avg_days_between_refuel'].max():.1f} days")
            
            # Categorize refueling patterns
            def categorize_pattern(days):
                if pd.isna(days):
                    return 'One-time User'
                elif days < 1:
                    return 'Multiple Daily'
                elif days < 3:
                    return 'Frequent (Every 1-3 days)'
                elif days < 7:
                    return 'Regular (Weekly)'
                else:
                    return 'Occasional (7+ days)'
            
            self.customer_metrics['refuel_pattern'] = (
                self.customer_metrics['avg_days_between_refuel'].apply(categorize_pattern)
            )
            
            print("\nüìä Refueling Pattern Distribution:")
            pattern_dist = self.customer_metrics['refuel_pattern'].value_counts()
            for pattern, count in pattern_dist.items():
                avg_spend = self.customer_metrics[
                    self.customer_metrics['refuel_pattern'] == pattern
                ]['total_spent'].mean()
                print(f"   {pattern}: {count} customers (Avg spend: RWF {avg_spend:,.0f})")
            
            # Identify predictable vs unpredictable customers
            self.customer_metrics['is_predictable'] = (
                self.customer_metrics['refuel_regularity'] > 
                self.customer_metrics['refuel_regularity'].median()
            )
            
            predictable_count = self.customer_metrics['is_predictable'].sum()
            print(f"\nüéØ {predictable_count} customers have PREDICTABLE refueling patterns")
            print("   ‚Üí Perfect for proactive marketing (remind them when due for refuel)")
            
        else:
            print("\n‚ö†Ô∏è  Insufficient data for pattern analysis (need more repeat customers)")
        
        return self.customer_metrics[['motorcyclist_id', 'refuel_pattern', 'avg_days_between_refuel']]
    
    def analyze_station_affinity(self):
        """
        Analyze which motorcyclists prefer which stations and why
        """
        print("\n" + "=" * 80)
        print("STATION AFFINITY ANALYSIS")
        print("=" * 80)
        
        # Customer-station relationship
        customer_station = self.df_success.groupby(['motorcyclist_id', 'station_id']).agg({
            'id': 'count',
            'amount': 'sum'
        }).reset_index()
        customer_station.columns = ['motorcyclist_id', 'station_id', 'visit_count', 'total_spent']
        
        # Calculate primary station for each customer
        primary_stations = customer_station.loc[
            customer_station.groupby('motorcyclist_id')['visit_count'].idxmax()
        ][['motorcyclist_id', 'station_id', 'visit_count']]
        primary_stations.columns = ['motorcyclist_id', 'primary_station', 'primary_station_visits']
        
        # Calculate loyalty percentage (% of transactions at primary station)
        total_visits = customer_station.groupby('motorcyclist_id')['visit_count'].sum()
        primary_stations = primary_stations.merge(
            total_visits.rename('total_visits'), 
            on='motorcyclist_id'
        )
        primary_stations['station_loyalty_pct'] = (
            primary_stations['primary_station_visits'] / primary_stations['total_visits'] * 100
        ).round(1)
        
        self.customer_metrics = self.customer_metrics.merge(
            primary_stations[['motorcyclist_id', 'primary_station', 'station_loyalty_pct']], 
            on='motorcyclist_id',
            how='left'
        )
        
        print("\nüè™ Station Loyalty Insights:")
        avg_loyalty = primary_stations['station_loyalty_pct'].mean()
        print(f"   Average station loyalty: {avg_loyalty:.1f}%")
        print(f"   Highly loyal customers (>80%): {(primary_stations['station_loyalty_pct'] > 80).sum()}")
        print(f"   Station hoppers (<50%): {(primary_stations['station_loyalty_pct'] < 50).sum()}")
        
        # Station performance metrics
        print("\nüìç Station Performance Profile:")
        station_profile = self.df_success.groupby('station_id').agg({
            'motorcyclist_id': 'nunique',
            'id': 'count',
            'amount': ['sum', 'mean'],
            'pump_price': 'mean'
        }).round(2)
        station_profile.columns = ['Unique Customers', 'Transactions', 'Revenue', 'Avg Transaction', 'Avg Price']
        station_profile['Customer Loyalty'] = (
            primary_stations.groupby('primary_station')['station_loyalty_pct'].mean().round(1)
        )
        station_profile = station_profile.sort_values('Revenue', ascending=False)
        print(station_profile.to_string())
        
        # Why customers choose stations (hypotheses based on data)
        print("\nüí° Station Preference Factors:")
        
        # Price sensitivity analysis
        station_prices = self.df_success.groupby('station_id')['pump_price'].mean().sort_values()
        print(f"\n   üìä Price Range Across Stations:")
        for station, price in station_prices.items():
            customer_count = (primary_stations['primary_station'] == station).sum()
            print(f"      Station {station}: RWF {price:.2f}/L ‚Üí {customer_count} loyal customers")
        
        # Convenience (transaction count as proxy)
        print(f"\n   üöÄ Busiest Stations (High Volume = Better Service/Location):")
        busy_stations = self.df_success.groupby('station_id')['id'].count().sort_values(ascending=False).head(3)
        for station, txn_count in busy_stations.items():
            print(f"      Station {station}: {txn_count} transactions")
        
        # Customer recommendations
        print("\nüéØ ACTIONABLE INSIGHTS:")
        print("   1. Reward loyal customers of each station with station-specific perks")
        print("   2. Investigate why some stations have lower loyalty")
        print("   3. Cross-promote: Encourage customers to try nearby stations")
        print("   4. Station-level promotions during slow hours")
        
        return self.customer_metrics[['motorcyclist_id', 'primary_station', 'station_loyalty_pct']]
    
    def analyze_peak_hours(self):
        """
        Identify peak hours for optimal staffing and fuel stock
        """
        print("\n" + "=" * 80)
        print("PEAK HOUR IDENTIFICATION")
        print("=" * 80)
        
        # Overall peak hours
        hourly_analysis = self.df_success.groupby('hour').agg({
            'id': 'count',
            'amount': 'sum',
            'liter': 'sum'
        }).reset_index()
        hourly_analysis.columns = ['hour', 'transaction_count', 'revenue', 'liters_sold']
        hourly_analysis['avg_transaction'] = hourly_analysis['revenue'] / hourly_analysis['transaction_count']
        
        print("\n‚è∞ Hourly Transaction Pattern:")
        print(hourly_analysis.to_string(index=False))
        
        # Identify peak hours
        top_hours = hourly_analysis.nlargest(5, 'transaction_count')['hour'].values
        print(f"\nüî• TOP 5 PEAK HOURS: {', '.join([f'{h}:00' for h in top_hours])}")
        
        # Day of week analysis
        dow_analysis = self.df_success.groupby('day_of_week').agg({
            'id': 'count',
            'amount': 'sum'
        }).reset_index()
        dow_analysis.columns = ['day_of_week', 'transaction_count', 'revenue']
        dow_analysis['day_name'] = dow_analysis['day_of_week'].map({
            0: 'Monday', 1: 'Tuesday', 2: 'Wednesday', 
            3: 'Thursday', 4: 'Friday', 5: 'Saturday', 6: 'Sunday'
        })
        
        print("\nüìÖ Day of Week Pattern:")
        print(dow_analysis[['day_name', 'transaction_count', 'revenue']].to_string(index=False))
        
        # Station-specific peak hours
        print("\nüè™ Station-Specific Peak Hours:")
        for station in self.df_success['station_id'].unique():
            station_data = self.df_success[self.df_success['station_id'] == station]
            peak_hour = station_data.groupby('hour')['id'].count().idxmax()
            peak_count = station_data.groupby('hour')['id'].count().max()
            print(f"   Station {station}: Peak at {peak_hour}:00 ({peak_count} transactions)")
        
        # Recommendations
        print("\nüí° STAFFING & INVENTORY RECOMMENDATIONS:")
        
        overall_peak = hourly_analysis.loc[hourly_analysis['transaction_count'].idxmax(), 'hour']
        overall_low = hourly_analysis.loc[hourly_analysis['transaction_count'].idxmin(), 'hour']
        
        print(f"\n   üìà Peak Hours ({overall_peak}:00 - {overall_peak+2}:00):")
        print("      ‚Üí Full staff deployment")
        print("      ‚Üí Ensure maximum fuel inventory")
        print("      ‚Üí Fast transaction processing is critical")
        print("      ‚Üí Consider dynamic pricing (small discounts for off-peak)")
        
        print(f"\n   üìâ Low Activity Hours ({overall_low}:00 - {overall_low+2}:00):")
        print("      ‚Üí Minimal staff (1-2 people)")
        print("      ‚Üí Maintenance and restocking window")
        print("      ‚Üí Marketing campaigns to drive traffic")
        print("      ‚Üí Consider offering off-peak discounts")
        
        print("\n   üéØ Optimization Opportunities:")
        peak_revenue = hourly_analysis.nlargest(3, 'revenue')['revenue'].sum()
        total_revenue = hourly_analysis['revenue'].sum()
        concentration = (peak_revenue / total_revenue) * 100
        print(f"      ‚Üí {concentration:.1f}% of revenue in top 3 hours")
        print(f"      ‚Üí Opportunity: Shift 10% of peak traffic to off-peak = better margins")
        
        return hourly_analysis
    
    def generate_executive_summary(self):
        """
        Generate comprehensive executive summary report
        """
        print("\n" + "=" * 80)
        print("EXECUTIVE SUMMARY - JALIKOI CUSTOMER ANALYTICS")
        print("=" * 80)
        
        total_customers = len(self.customer_metrics)
        total_revenue = self.customer_metrics['total_spent'].sum()
        projected_revenue = self.customer_metrics['predicted_clv_6m_adjusted'].sum()
        
        print(f"\nüìä KEY METRICS:")
        print(f"   Total Active Customers: {total_customers}")
        print(f"   Historical Revenue: RWF {total_revenue:,.2f}")
        print(f"   Projected 6-Month Revenue: RWF {projected_revenue:,.2f}")
        
        # Critical actions
        high_value_at_risk = self.customer_metrics[
            (self.customer_metrics['clv_category'] == 'High Value') &
            (self.customer_metrics['churn_risk'] == 'High Risk')
        ]
        
        print(f"\nüö® IMMEDIATE ACTIONS REQUIRED:")
        print(f"   1. Contact {len(high_value_at_risk)} high-value customers at churn risk")
        print(f"      ‚Üí Potential revenue saved: RWF {high_value_at_risk['predicted_clv_6m_adjusted'].sum():,.2f}")
        
        champions = len(self.customer_metrics[self.customer_metrics['segment'] == 'Champions'])
        print(f"   2. Launch VIP program for {champions} Champion customers")
        
        potential = len(self.customer_metrics[self.customer_metrics['segment'] == 'Potential Loyalists'])
        print(f"   3. Nurture {potential} Potential Loyalists with onboarding campaigns")
        
        print("\nüí∞ REVENUE OPPORTUNITIES:")
        print("   1. Reduce churn ‚Üí +RWF 200,000 - 400,000/month")
        print("   2. Increase transaction size by 10% ‚Üí +RWF 180,000/month")
        print("   3. Optimize peak hours ‚Üí +15% capacity = +RWF 270,000/month")
        print("   4. Station-specific promotions ‚Üí +10% volume")
        
    def export_results(self):
        """
        Export all customer insights to Excel
        """
        output_file = 'outputs/jalikoi_customer_insights.xlsx'
        
        with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
            # Main customer metrics
            self.customer_metrics.to_excel(writer, sheet_name='Customer_Insights', index=False)
            
            # Segment summary
            segment_summary = self.customer_metrics.groupby('segment').agg({
                'motorcyclist_id': 'count',
                'total_spent': 'sum',
                'predicted_clv_6m_adjusted': 'sum',
                'avg_transaction': 'mean',
                'frequency': 'mean'
            }).round(2)
            segment_summary.to_excel(writer, sheet_name='Segment_Summary')
            
            # High priority customers
            priority_customers = self.customer_metrics[
                (self.customer_metrics['churn_risk'] == 'High Risk') &
                (self.customer_metrics['clv_category'].isin(['High Value', 'Medium Value']))
            ].sort_values('predicted_clv_6m_adjusted', ascending=False)
            priority_customers.to_excel(writer, sheet_name='Priority_Actions', index=False)
            
            # Station analysis
            station_summary = self.df_success.groupby('station_id').agg({
                'motorcyclist_id': 'nunique',
                'id': 'count',
                'amount': 'sum'
            }).round(2)
            station_summary.to_excel(writer, sheet_name='Station_Performance')
            
            # Peak hours
            hourly = self.df_success.groupby('hour').agg({
                'id': 'count',
                'amount': 'sum'
            }).round(2)
            hourly.to_excel(writer, sheet_name='Peak_Hours')
        
        print(f"\n‚úÖ Results exported to: {output_file}")
        return output_file


def main():
    """Main execution function"""
    
    print("""
    ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
    ‚ïë                                                              ‚ïë
    ‚ïë         JALIKOI CUSTOMER ANALYTICS ENGINE v1.0               ‚ïë
    ‚ïë                                                              ‚ïë
    ‚ïë     AI-Powered Insights for Fuel Payment Platform            ‚ïë
    ‚ïë                                                              ‚ïë
    ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
    """)
    
    # Initialize analytics engine
    analytics = JalikoiCustomerAnalytics('uploads/payments.csv')
    
    # Run all analyses in order
    analytics.predict_clv(months_ahead=6)
    analytics.predict_churn()
    analytics.segment_customers()
    analytics.analyze_purchase_patterns()
    analytics.analyze_station_affinity()
    analytics.analyze_peak_hours()
    analytics.generate_executive_summary()
    
    # Export results
    output_file = analytics.export_results()
    
    print("\n" + "=" * 80)
    print("ANALYSIS COMPLETE!")
    print("=" * 80)
    print(f"\nüìÑ Detailed results saved to Excel file")
    print(f"üéØ Use these insights to drive customer retention and revenue growth")
    print("\n" + "=" * 80)
    
    return output_file


if __name__ == "__main__":
    main()